# DB/빅데이터

<br>

### 빅데이터 에코시스템

**1. 데이터 수집**

* 비정형 데이터
  * 척와
    * 분산된 각 서버에서 에이전트 실행, 컬렉터가 모아서 저장
  * Flume
    * 로그데이터 수집
    * 에이전트, 이벤트 활용
  * Scribe
    * 대용량 실시간 로그 데이터 수집
* 정형 데이터
  * Sqoop
    * SQL to Hadoop
    * 커넥터를 사용하여 RDBMS로 부터 HDFS로 데이터를 수집한다
  * Hiho

**2. 데이터 처리**

* Map Reduce
  * map, shuffle, reduce 활용

**3. 데이터 저장**

* HDFS(분산 데이터 저장)
* Hbase(분산 데이터베이스)

**4. 데이터 가공(DW)**

* Hive
  * 하둡 에코시스템 중에서 데이터를 모델링하고 프로세싱하는 경우 가장 많이 사용하는 **데이터 웨어하우스** 솔루션
  * 아파치 하이브는 아파치 HDFS이나 아파치 HBase와 같은 데이터 자장 시스템에 저장되어 있는 대용량 데이터 집합들을 분석한다.
  * HiveQL이라고 불리는 SQL같은 언어를 제공하며 맵리듀스의 모든 기능을 지원한다.
  * 쿼리를 빠르게 하기위해 비트맵 인덱스를 포함하여 인덱스 기능을 제공한다.
* Tajo

**5. 기타**

* YARN(리소스 관리)
* Impala(실시간 SQL 질의)
* Oozie(워크플로우, 자바서블릿)
* Zookeeper(분산코디네이션, 서버간 분산)
* Kafka(분산메시지처리)

<br>

---

### 빅데이터 분석

* 빅데이터 분석 방법론의 계층
  * Phase
    * 프로세스 그룹을 통하여 완성된 단계별 산출물이 생성, 기준선(Baseline)으로 설정 관리하며, 버전관리(Configuration Management) 등을 통한 통제
  * Task
    * Task를 구성하는 단위활동, 물리적 또는 논리적 단위로 품질 검토의 항목
  * Step
    * WBS(Work Breakdown Structure)의 워크패키지(Work Package)에 해당되고 입력자료(Input), 처리 및 도구(Process & Tool), 출력자료(Output)로 구성된 단위 프로세스(Unit Process)
* KDD 방법론
  * 데이터 셋 선택 - 전처리 - 변환 - 마이닝 - 마이닝 결과 평가
* CRISP-DM
  * 업무 이해 - 데이터 이해 - 데이터 준비 - 모델링 - 평가- 전개
* SEMMA
  * 샘플링 - 탐색 - 수정 - 모델링 - 검증

<br>

---

### HDFS

> Hadoop Distributed File System, 범용 하드웨어에서 동작하고, 장애 복구성을 가지는 분산 파일 시스템을 목표로 한다

* 특징

  * 블록단위 저장
  
* 블록 복제를 이용한 장애 복구
    * 블록의 기본 복제 단위는 3
    * 하나의 블록은 3개의 블록으로 복제되고, 같은 랙(Rack)의 서버와 다른 랙(Rack)의 서버로 복제되어 저장된다
    * 1G의 데이터를 저장할 때 데이터가 복제되어 3G의 저장공간이 필요
  * 읽기 중심
    * HDFS는 데이터를 한 번 쓰면 여러 번 읽는 것을 목적
    * 수정할 수 없음, 파일의 수정을 제한하여 동작을 단순화하고 이를 통해 데이터를 읽을 때 속도를 높일 수 있다
  * 데이터 지역성
    * 처리 알고리즘이 있는 곳에 데이터를 이동시키지 않고, 데이터가 있는 곳에서 알고리즘을 처리하여 네트워크를 통해 대용량 데이터를 이동시키는 비용을 줄일 수 있다
  
* 구조

    <img src = "https://user-images.githubusercontent.com/75229881/116204621-ec292b80-a777-11eb-9b81-c0cc7f30d609.png" width="80%">

* 일반적으로 HDFS 클러스터는 하나의 네임노드(Name Node)와 여러개의 데이터노드(Data Node)로 구성된다(Master/Slave 구조)

* 네임노드

    * 메타데이터 관리와 데이터노드의 관리

      ```
      1. Fsimage를 읽어 메모리에 적재
      2. Edits 파일을 읽어와서 변경내역을 반영
      3. 현재의 메모리 상태를 스냅샷으로 생성하여 Fsimage 파일 생성
      4. 데이터 노드로부터 블록리포트를 수신하여 매핑정보 생성
      5. 서비스 시작
      ```

    * 메타데이터 관리
        * 메타데이터는 파일이름, 파일크기, 파일생성시간, 파일접근권한, 파일 소유자 및 그룹 소유자, 파일이 위치한 블록의 정보 등으로 구성
        * Fsimage 파일 : 네임스페이스와 블록 정보
        * Edits 파일 : 파일의 생성, 삭제에 대한 트랜잭션 로그

    * 데이터 노드 관리

        * 네임노드는 데이터노드가 주기적으로 전달하는 하트비트(3초)와 블록리포트(6시간)를 이용하여 데이터 노드의 동작상태, 블록상태를 관리

<br>

---

### Map Reduce

> 맵리듀스는 간단한 단위작업을 반복하여 처리할 때 사용하는 프로그래밍 모델이다. 간단한 단위작업을 처리하는 맵(Map) 작업과 맵 작업의 결과물을 모아서 집계하는 리듀스(Reduce) 단계로 구성

**처리단계**

1. 입력
   * 데이터를 입력하는 단계
   * 텍스트, csv, gzip 형태의 데이터를 읽어서 맵으로 전달

2. 맵(Map)
   * 입력을 분할하여 키별로 데이터를 처리

3. 컴바이너(Combiner)
   * 네트워크를 타고 넘어가는 데이터를 줄이기 위하여 맵의 결과를 정리
   * 로컬 리듀서라고도 함
   * 컴바이너는 작업의 설정에 따라 없을 수도 있음

4. 파티셔너(Partitoner)
   * 맵의 출력 결과 키 값을 해쉬 처리하여 어떤 리듀서로 넘길지를 결정

5. 셔플(Shuffle)
   * 각 리듀서로 데이터 이동

6. 정렬(Sort)
   * 리듀서로 전달된 데이터를 키 값 기준으로 정렬

7. 리듀서(Reduce)
   * 리듀서로 데이터를 처리하고 결과를 저장

8. 출력
   * 리듀서의 결과를 정의된 형태로 저장

**예제**

<img src = "https://user-images.githubusercontent.com/75229881/116203909-27772a80-a777-11eb-8655-0895262cf03d.png" width="80%">





---

### 연관규칙

* 연관규칙분석의 대표적인 알고리즘
  * **Apriori algorithm** : [[Python\] Apriori algorithm:: 연관규칙분석 (1) (tistory.com)](https://ordo.tistory.com/89)
  * **FP-growth algorithm**
  * **DHP algorithm**

**지지도**

* 전체 거래 중 항목집합 X, Y를 모두 포함하는 거래비율
* P(X and Y) / All

**신뢰도**

* 항목집합 X를 포함하는 거래 중 Y도 포함하는 거래비율
* P(X and Y) /  P(X)

---

### DW

**특징**

* 주제지향 : 의사결정에 필요한 특정 주제의 데이터만을 저장
* 통합적 : 데이터의 정합성과 물리적 통일성을 갖는 구조
* 시계열적 : 데이터를 일련의 스냅샷 형태로 오랜기간 보유
* 비소멸성 : 한번 적재되면 이후에 삭제 및 수정이 불가능하다.

---

### OLAP

**Operation**

1. **Roll-up**
   * 작은단위에서 큰 단위
   * (예 : month, year)로 집계 수행
2. **Drill-down**
   * 큰 단위에서 작은 단위
   * (예: month, day)로 집계 수행
3. **Slice and dice**
   * Slice : 하나 혹은 그 이상의 축으로 셀들을 선택 - 단순필터
   * Dice : 속성 값의 범위를 명시하여 셀들의 부분집합(부분큐브)을 선택 - 복합필터
4. **Pivot**
   * 데이터의 축을 변경하여 데이터를 표현

---
