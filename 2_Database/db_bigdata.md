# DB/빅데이터

<br>

### HDFS

> Hadoop Distributed File System, 범용 하드웨어에서 동작하고, 장애 복구성을 가지는 분산 파일 시스템을 목표로 한다

* 특징

  * 블록단위 저장
  
* 블록 복제를 이용한 장애 복구
    * 블록의 기본 복제 단위는 3
    * 하나의 블록은 3개의 블록으로 복제되고, 같은 랙(Rack)의 서버와 다른 랙(Rack)의 서버로 복제되어 저장된다
    * 1G의 데이터를 저장할 때 데이터가 복제되어 3G의 저장공간이 필요
  * 읽기 중심
    * HDFS는 데이터를 한 번 쓰면 여러 번 읽는 것을 목적
    * 수정할 수 없음, 파일의 수정을 제한하여 동작을 단순화하고 이를 통해 데이터를 읽을 때 속도를 높일 수 있다
  * 데이터 지역성
    * 처리 알고리즘이 있는 곳에 데이터를 이동시키지 않고, 데이터가 있는 곳에서 알고리즘을 처리하여 네트워크를 통해 대용량 데이터를 이동시키는 비용을 줄일 수 있다
  
* 구조

    <img src = "https://user-images.githubusercontent.com/75229881/116204621-ec292b80-a777-11eb-9b81-c0cc7f30d609.png" width="80%">

* 일반적으로 HDFS 클러스터는 하나의 네임노드(Name Node)와 여러개의 데이터노드(Data Node)로 구성된다(Master/Slave 구조)

* 네임노드

    * 메타데이터 관리와 데이터노드의 관리

      ```
      1. Fsimage를 읽어 메모리에 적재
      2. Edits 파일을 읽어와서 변경내역을 반영
      3. 현재의 메모리 상태를 스냅샷으로 생성하여 Fsimage 파일 생성
      4. 데이터 노드로부터 블록리포트를 수신하여 매핑정보 생성
      5. 서비스 시작
      ```

    * 메타데이터 관리
        * 메타데이터는 파일이름, 파일크기, 파일생성시간, 파일접근권한, 파일 소유자 및 그룹 소유자, 파일이 위치한 블록의 정보 등으로 구성
        * Fsimage 파일 : 네임스페이스와 블록 정보
        * Edits 파일 : 파일의 생성, 삭제에 대한 트랜잭션 로그

    * 데이터 노드 관리

        * 네임노드는 데이터노드가 주기적으로 전달하는 하트비트(3초)와 블록리포트(6시간)를 이용하여 데이터 노드의 동작상태, 블록상태를 관리

---

### Map Reduce

> 맵리듀스는 간단한 단위작업을 반복하여 처리할 때 사용하는 프로그래밍 모델이다. 간단한 단위작업을 처리하는 맵(Map) 작업과 맵 작업의 결과물을 모아서 집계하는 리듀스(Reduce) 단계로 구성

**처리단계**

1. 입력
   * 데이터를 입력하는 단계
   * 텍스트, csv, gzip 형태의 데이터를 읽어서 맵으로 전달

2. 맵(Map)
   * 입력을 분할하여 키별로 데이터를 처리

3. 컴바이너(Combiner)
   * 네트워크를 타고 넘어가는 데이터를 줄이기 위하여 맵의 결과를 정리
   * 로컬 리듀서라고도 함
   * 컴바이너는 작업의 설정에 따라 없을 수도 있음

4. 파티셔너(Partitoner)
   * 맵의 출력 결과 키 값을 해쉬 처리하여 어떤 리듀서로 넘길지를 결정

5. 셔플(Shuffle)
   * 각 리듀서로 데이터 이동

6. 정렬(Sort)
   * 리듀서로 전달된 데이터를 키 값 기준으로 정렬

7. 리듀서(Reduce)
   * 리듀서로 데이터를 처리하고 결과를 저장

8. 출력
   * 리듀서의 결과를 정의된 형태로 저장

**예제**

<img src = "https://user-images.githubusercontent.com/75229881/116203909-27772a80-a777-11eb-8655-0895262cf03d.png" width="80%">



---

### 빅데이터 에코시스템

**Hive**

* 하둡 에코시스템 중에서 데이터를 모델링하고 프로세싱하는 경우 가장 많이 사용하는 **데이터 웨어하우스** 솔루션
* 아파치 하이브는 아파치 HDFS이나 아파치 HBase와 같은 데이터 자장 시스템에 저장되어 있는 대용량 데이터 집합들을 분석한다.
* HiveQL이라고 불리는 SQL같은 언어를 제공하며 맵리듀스의 모든 기능을 지원한다.
* 쿼리를 빠르게 하기위해 비트맵 인덱스를 포함하여 인덱스 기능을 제공한다.

**Kafka**

* LinkedIn에서 개발한 분산 스트리밍 플랫폼입니다. 메시징, 메트릭 수집, 로그 수집, 스트림 처리 등 다양한 용도로 사용할 수 있다.

**Sqoop**

* Sqoop은 관계형 데이터베이스와 하둡 HDFS간에 데이터를 전송할 수 있도록 설계된 오픈소스 소프트웨어

---

### 연관규칙

**지지도**

* 전체 거래 중 항목집합 X, Y를 모두 포함하는 거래비율
* P(X and Y)

**신뢰도**

* 항목집합 X를 포함하는 거래 중 Y도 포함하는 거래비율
* P(X and Y) /  P(X)

---

### DW

**특징**

* 주제지향 : 의사결정에 필요한 특정 주제의 데이터만을 저장
* 통합적 : 데이터의 정합성과 물리적 통일성을 갖는 구조
* 시계열적 : 데이터를 일련의 스냅샷 형태로 오랜기간 보유
* 비소멸성 : 한번 적재되면 이후에 삭제 및 수정이 불가능하다.

---

