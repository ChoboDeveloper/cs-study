# Operation System

<br>

---

### 제어장치의 구성요소
* 명령 계수기(PC) 
  * 다음에 실행할 명령의 주소기억
* 주소 레지스터(MAR)
  * 주기억장치에 선택될 주소를 기억하는 레지스터
* 내용 레지스터(MBR)
  * PC나 MAR이 지정하는 주기억장치의 내용을 임시로 기억하는 레지스터 
* 명령 레지스터(IR)
  * PC가 지정한 주소의 명령을 인출하여 명령 실행이 완료될 때 까지 명령을 보관하는 레지스터 
* 명령 해독기
  * IR에서 보내온 명령 코드를 해독
* 인덱스 레지스터(IX)
  * 명령 어드레스나 인덱스를 변경할 때 사용
* 제어신호 발생기(부호기)
  * 명령 해독기에서 보내온 신호를 명령을 실행하는데 필요한 신호로 바꾸어 각 장치에 제어신호 전송

---

### 프로세스

>프로세스 간: [코드, 데이터 영역, 힙, 스택] 모두를 비 공유
>스레드  : [코드, 데이터 영역, 힙, **스택**] 중 스택 영역만 비 공유

**프로세스 제어 블록(PCB)**

* 운영체제가 프로세스를 제어하기 위해 정보를 저장해 놓는 곳으로, 프로세스의 **상태 정보**를 저장하는 구조체이다.
* 프로세스 상태 관리와 **문맥교환(Context Switching)**을 위해 필요하다.
* PCB는 프로세스 생성 시 만들어지며 **주기억장치에 유지**된다.
* 구조
  * PID : 프로세스의 고유 번호
  * 상태 : 준비, 대기, 실행 등의 상태
  * Program Counter(**PC**) : 다음 실행될 프로세스의 포인터
  * Registers : 레지스터 관련 정보
  * Priority : 스케줄링 및 프로세스 우선순위
  * Memory : 할당된 자원 정보
  * Account : CPU 사용시간, 실제 사용된 시간
  * I/O : 입출력 상태 정보

**프로세스 생성**

* PID 1은 init 프로세스, 0은 특별한 목적으로 예약된 번호로 유휴 프로세스에 지정
* PID는 ps명령어를 통해 확인가능
  * PPID(부모의 PID)와 UID(사용자의 ID)까지 확인하기 위해 자세한 정보를 출력하기 위해서는 ps -f 사용
* fork()
  * 자식 프로세스 생성 성공 시 0, 실패시 -1 리턴
  * 부모 프로세스라면 양수를 리턴한다.

---

### 페이징

* 프로세스의 물리 주소 공간이 연속되지 않아도 되는 메모리 관리 기법

* 물리페이지는 frame, 논리메모리는 page로 분할된다

* 페이지가 하나의 프레임을 할당 받으면, 물리 메모리에 위치할 수 있게 된다. 이 페이지를 가상기억장치에 편성해 운용하는 기법을 페이징 기법이라고 한다. 

* 예제
  
  > \* 페이지 크기는 2000byte, 논리주소가 2500 
  >
  > \- 페이지번호는 1번임, 이에 해당하는 프레임번호가 3번, 오프셋은 500
  >
  > \- 물리주소는 6500
  >
  > \* 128MB의 물리 메모리를 4KB 단위로 페이징 하려고 하면, 몇 개의 frame이 필요 한가?
  >  \- 128 MB = 2^7 * 2^20 = 2^27
  >  \- 4KB = 2^2 * 2^10 = 2^12
  >  \- 2^27 / 2^12 = 2^15 = 32 K
  >  \- 즉, 32K 개의 프레임이 필요하다.
  >
  > \* CPU의 주소 버스가 32 bit인 시스템에서 4GB의 logical address를 페이징 하려고 하면, 총 몇 개의 page가 필요 한가?
  >  \- 페이지 크기는 4KB로 가정한다.
  >  \- 주소 공간의 크기는 2^32 바이트 = 4GB 이다.
  >  \- 전체 주소 공간을 페이지 크기로 나누면, 4GB / 4KB = 100,000
  >  \- 즉, 전체 페이지의 개수가 10만 개가 된다.
  >
  > \* page의 크기가 4KB일 때, 한 페이지의 메모리를 access하기 위한 주소 bit는 몇 비트인가?
  >  \- 12 비트
  
* 페이징 자체는 일종의 동적 재배치

* **MMU**를 활용하여 논리주소와 물리주소 변환

**주소표현**

* 페이지 번호(p)와 페이지 오프셋(d)
* 논리 주소 공간의 크기가 **2<sup>m</sup>**, 페이지의 크기가 **2<sup>n</sup>** 일 때, 상위 **(m-n)**비트는 **페이지 번호**, 하위 **n**비트는 **오프셋**
* 즉, p = m-n으로 표현,  d = n 비트로 표현

**요구페이징**

* 요구페이징은 필요한 프로그램만 메모리에 적재하는 방법으로 가상 메모리 시스템에서 많이 사용된다. 
* 요구 페이징을 사용하는 가상메모리에서는 페이지들이 실행 과정에서 실제로 필요해질 때 적재 된다.

---

### 단편화

* 내부단편화
* 외부단편화
  * 세그먼테이션 사용 시, 남은 메모리 공간은 충분한 공간이 있으나 조각나서 할당이 불가한 상태 

---

### RAID

* RAID 0 (스트라이핑)
  * 읽기/쓰기 n배 상향
  * 디스크 수 * Disk 용량
  * 낮은 안정성
* RAID 1 (미러링)
  * 읽기 n배 상향, 쓰기 시 성능 감소
  * 디스크 수 /2 * 용량
  * 높은 안정성
* RAID 2
  * 해밍코드
* RAID 3/4
  * 데이터 스트라이핑 및 별도의 Parity disk 사용
  * 3 - byte 단위 / 4 - block 단위
* RAID 5
  *  Block 레벨의 Striping과 Parity 사용(Parity 분산 제공)
  * 읽기 N배, 쓰기 성능이 (N-1)배 향상
* RAID 6
  *  Block 레벨의 Striping과 Double Parity 사용(Parity 분산 제공)
  * 읽기 N배, 쓰기 성능이 (N-2)배 향상

---

### 프로세스 스케줄링

**비선점**

* FCFS
* SJF
  * 실행시간이 짧은 스케줄 먼저 실행
* HRN
  * (대기시간 + 실행시간) / 실행시간으로 우선순위를 결정, 높을수록 우선순위가 높음
  * **(대+실)/실**

**선점**

* RR
  * 각 프로세스마다 동일한 실행시간 부여
  * Clock 인터럽트를 필요로 한다.
* SRT
  * SJF와 비슷하나 짧은 스케줄이 들어왔을 때 선점가능
  * **큐에 새로운 프로세스가 들어왔을 때**, 실행중인 프로세스와 대기중인 프로세스의 실행시간을 비교
* Multi-Level Queue
  * 여러 큐를 형성하여 높은 우선순위의 큐에 있는 작업이 우선순위를 가진다.
* Multi-Level Feedback Queue
  * 각 큐에 time-quantum을 적용하여 실행시간이 길어지면 아래 큐로 보낸다.
  * 보통 밑으로 갈수록 time이 길고 마지막에는 FCFS로 처리

---

### 페이지 교체 기법

* FIFO
* OPT
  * 앞으로 가장 사용되지 않을 페이지 교체
* LRU
* LFU
  * 참조비트 사용
* NUR
  * 참조비트와 변형비트를 사용
  * 변형비트는 페이지가 수정되었을 때 1로 set
  * 참조비트가 변형비트보다 우선순위가 높다
  * **NUR -> R/R(1.Reference/2.Replace)**
* SCR(Second-Chance Replacement)
  * FIFO에서 참조된 페이지는 Reference bit을 1로 설정하고 만약 1일 때, 교체대상이라면 0으로 설정하고 한 번의 기회를 부여

---

### 하드디스크

**스케줄링 기법**

* FCFS

* SSTF 

* SCAN

  * 좌우 왕복하면서 가는 길에 처리한다

  ![image](https://user-images.githubusercontent.com/75229881/110737022-fa76c300-826f-11eb-960a-27499f930912.png)

  > N-step-SCAN
  >
  > 디스크 헤더가 n개의 요청만 받아들이고 이들만 수행한다
  >
  > 만약 n이 엄청 큰 숫자이면 SCAN과 다를게 없고, n이 1이면 FCFS와 다를게 없다
  >
  > *response-time-interval*을 줄일 수 있다

* C-SCAN

  * 한 쪽 방향으로만 이동한다

  ![image](https://user-images.githubusercontent.com/75229881/110737211-4a558a00-8270-11eb-896a-7a7f71f22823.png)

* LOOK/C-LOOK

  * 끝까지는 안간다
  * C-LOOK은 한 쪽 방향으로 움직인다
  
  ![image](https://user-images.githubusercontent.com/75229881/110737261-63f6d180-8270-11eb-8cbf-d2e8dff088c7.png)

<br>

**헤드방식**

* **고정헤드**는 헤드가 여러개 달려있다. 때문에 헤드를 움직일 필요가 없어서 섹터에 빠른 접근이 가능하다. 따라서 여러개의 원판으로 구성된 대용량 디스크에 적합하다.
* **이동헤드**는 헤드가 하나가 달려있기 때문에 원하는 섹터의 위치로 이동을 해야한다.

**디스크 인터리빙**

* DC모터는 특성상 돌다가 멈춰도 속도에 의해 계속해서 돌게 된다. 따라서 **디스크를 읽은 후 데이터를 전송하는 동안 디스크가** 멈춰있는 것이 아니라 돌기 때문에 섹터번호가 붙어있게되면 다음 섹터번호를 읽을 때 디스크를 한바퀴 더 돌려야하는 불필요한 수행을 해야하기 때문에 불리하다.
* 따라서 **섹터번호 할당에 간격을 두게 되는데 이를 디스크 인터리빙**이라고 한다.0

---

### CISC/RISC

**CISC**

* 명령어의 개수가 다양하며 길이는 가변적
* 고급언어에 대해 각각 기계어가 대응되도록 하는 것, 복잡한 구조를 가진다.
* 복잡한 컴파일러, 회로구성 복잡
* 복잡한 명령이 많기 때문에 마이크로 프로그램으로 제어한다.

**RISC**

* 명령어의 개수가 적으며 고정 길이를 가진다.
* 단순한 컴파일러, 회로구성 단순
* 단순 명령이 많기 때문에 다수의 레지스터가 필요하고 하드와이어(Hard-wired)방식으로 제어한다.

---

### 프로세스 상태전이

![process_state](https://user-images.githubusercontent.com/75229881/113966976-0ce21d80-986b-11eb-9bf5-e879ae14dc4d.png)

* 상태전이
  * Dispatch - 프로세스 스케줄러에 의해 결정된 우선순위에 따라 프로세스가 CPU를 점유하게 되는 상태
  * Time out - 프로세스가 실행중이다가 제한된 시간을 다 소비하여 CPU 점유를 빼앗기는 상태
  * Block - 실행중이던 프로세스가 외부 요인에 의해서 자원을 빼앗기는 상태
  * Wake up - 프로세스가 자원을 할당받는 상태
  * Swap in - 프로세스가 주기억장치에 적재 되는 상태
  * Swap out - 프로세스가 주기억장치에서 해제 되는 상태
* Ready 상태로의 전이
  * Running에서 Time-out
  * Asleep(I/O등의 이유로 Block됨)에서 Wake-up
  * 우선순위에 의하여 선점당했을 때

---

### 캐시

* 태그 필드
  * Tag는 현재 캐시블록에 주소값에 맞는 메모리 페이지인지 확인하는 값

* 라인 필드
  * 블록의 크기만큼의 라인을 가짐

* 단어/오프셋 필드
  * 블록 내부 워드의 offset 값
    * 블록은 다수의 word로 구성

<br>

**매핑방식**

![image](https://user-images.githubusercontent.com/75229881/114500782-bb1f0600-9c63-11eb-9a73-416a15fb779a.png)

* 직접사상

  * 태그 필드에서 해당 블록의 위치를 지정
  * 라인 필드에서 라인을 지정(블록크기와 동일)
  * 단어 필드(데이터)
  * 메모리 주소와 캐시의 순서를 일치시킨다. 메모리가 1~100까지 있고 캐시가 1~10까지 있다면 1~10까지의 메모리는 캐시의 1에 위치하고 11~20까지의 메모리는 캐시의 2에 위치시키는 것이다. 구현이 정말 간단하지만 저 규칙을 만족시켜서 캐시를 넣다 보면 캐시가 효율적이지 않게 자꾸 교체되어야 하는 일이 생긴다. 

![image](https://user-images.githubusercontent.com/75229881/114502916-79905a00-9c67-11eb-89c9-96e026cac12c.png)

* 연관사상

  * 블록으로 안나누고 태그가 하나의 Word의 주소를 가진다
  * 순서를 일치시키지 않는다. 필요한 메모리값을 캐시의 어디든 편하게 저장 될 수 있다. 당연히 찾는 과정은 복잡하고 느릴 수 있지만 정말 필요한 캐시들 위주로 저장할 수 있기 때문에 적중률은 높다. 캐시가 일반 메모리보다 속도가 훨씬 빠르므로 캐시의 검색량을 신경쓰는 것 보단 적중률이 높은게 성능이 더 좋다.

![image](https://user-images.githubusercontent.com/75229881/114503120-c2e0a980-9c67-11eb-8a12-da0b01bf4837.png)

* 세트-연관 사상

  * 세트는 블록의 묶음(2-way면 2라인을 가진다)
  * (t+d) 비트가 주기억장치의 2<sup>(t+d)</sup>를 가리킨다
  * 연관매핑에 직접매핑을 합쳐 놓은 방식이다. 순서를 일치시키고 편하게 저장하되, 일정 그룹을 두어 그 그룹 내에서 편하게 저장시키는 것이다. 예를 들면 메모리가 1~100까지 있고 캐시가 1~10까지 있다면 캐시 1~5에는 1~50의 데이터를 무작위로 저장시키는 것이다. 블록화가 되어 있기 때문에 검색은 좀 더 효율적으로 되고 직접매핑처럼 저장위치에 대한 큰 제약이 있는건 아니기 때문에 적중률이 많이 떨어지지도 않는다. 

```
만약 캐시 메모리 크기가 64Kb이고 캐시 블록의 크기가 32byte이다.
그리고 4-way 집합연관 사상한다면
블록의 크기는 2의 11승이 되고 이를 4개의 라인으로 나누기 때문에 총 512개의 set이 생성된다
따라서, set의 주소필드 크기는 9bit가 필요하다
```
**저장방식**

* Write-through
  * 캐시와 메모리 동시에 저장
  * 데이터 불일치 문제가 없지만 속도느려짐
* Write-back
  * 캐시에 적재 후 캐시에서 버릴 때, 메모리에 저장하는 방식
  * 데이터 불일치(캐시와 메모리 값이 다름)

**지역성**

* Hit Ratio를 높이기 위해서는 데이터의 지역성을 가져야 한다. 즉, 데이터 접근이 시간적, 공간적으로 가깝게 일어나야 한다.
* 시간적 지역성
  * 특정 데이터가 한번 접근되었을 경우, 가까운 미래에 또 한번 데이터에 접근할 가능성이 높은 것
  * 메모리 상의 같은 주소에 여러 차례 읽기 쓰기를 수행할 경우
  * 반복, 스택 등
* 공간적 지역성
  * 특정 데이터와 가까운 주소가 순서대로 접근되었을 경우

**일관성**

* 디렉토리 기반(directory-based) 프로토콜
* 스누핑(snooping) 프로토콜
* MESI 프로토콜

---

### I-node

**구성**

- 파일 모드
- 소유자명
- 그룹명
- 파일 크기
- 마지막 접근 정보
- 마지막 수정 정보
- i-node 수정 정보

---

### 가상화

> 가상화란 가상화를 관리하는 소프트웨어(주로 Hypervisor)를 사용하여 하나의 물리적 머신에서 가상 머신(VM)을 만드는 프로세스

**Type1 : Native, Bare Metal Hypervisor** 

* Type1 가상화는 VMM(Virtual Machine Monitor)을 하드웨어상에 직접 동작을 시키므로  호스트OS가 필요없다.
* 호스트형 가상화에 비해 오버헤드가 적고 물리 컴퓨터 리소스의 관리가 유연한게 특징
* 자체적인 관리기능이 없어서 하드웨어 가상화 기술 지원을 필요로함(Intel-VT, AMD-V)
* KVM, Xen
* 전가상화(Full Virtualization)

  * 전체 하드웨어를 완전히 가상화하는 기술
  * 게스트 OS가 자신이 가상화 환경인지 모르는 상태를 의미하며, 그에 따라 가상화되지 않은 실제 하드웨어 명령을 직접 요청 하는 것처럼 동작한다.
  * 하이퍼바이저가 모든 요청을 처리해야하기 때문에 비교적 느리다.
* 반가상화(Para Virtualization)

  * 전가상화의 가장 큰 단점인 성능저하의 문제를 해결하기 위해 **하이퍼콜(Hyper Call)**이라는 인터페이스를 통해 하이퍼바이저에게 직접 요청을 날릴 수 있다.
  * 하이퍼바이저에게 Hyper Call 요청을 할 수 있도록 각 게스트 OS의 커널을 수정해야함
  * 쉽게 말하면 가상화된 각 OS들이 각각 다른 번역기를 갖고 있는 것

**Type2 : Hosted Hypervisor**

* Host OS위에 Guest OS가 구동되는 방식
* 오버헤드가 크다. 성능이 가장 떨어지는 방식
* 손쉽게 구축가능한 특징
* QEMU, Vmware Workstation

---

### I/O 제어방식

**Programmed I/O**

* 원하는 I/O가 완료되었는지 여부를 검사하기 위해 CPU가 상태 플래그를 계속 조사하여 I/O가 완료된 경우 MDR(MBR)과 AC 사이의 자료 전송을 CPU가 직접 처리하는 방식(**Polling 방식**)
* I/O 작업 시 CPU는 계속 I/O 작업에 관여해야 하기 때문에 다른 작업을 할 수 없음
* 입력의 완료를 알리기 위해 인터럽트가 필요 없는 대신 CPU가 지속적으로 입출력 완료 여부를 확인해야함
* 리소스가 많이 소요되지만 구현이 단순하다,

**Interrupt I/O**

* 데이터를 전송할 준비가 되면 I/O 인터페이스가 컴퓨터에게 알려 입출력이 이루어짐
* I/O 인터페이스는 CPU에게 인터럽트 신호를 보내 입출력이 있음을 알림
* CPU가 지속적으로 Flag를 검사하지 않아도 되기 때문에 Pragrammed I/O보다 효율적
* CPU가 입력을 지시한 후 워드의 입력이 이루어지는 사이 다른 작업(타 프로그램 실행)이 이루어짐

**DMA(Directed Memory Access)**

* 입출력 기기들이 CPU의 레지스터를 거치지 않고 직접 메모리를 엑세스하여 입출력 데이터 전송
* CPU는 I/O에 필요한 정보를 DMA 제어기에 알려 I/O 동작을 개시시킨 후, 다른 작업을 수행
* 입출력 자료 전송 시 CPU를 거치지 않기 때문에 CPU의 부담 없이 빠른 데이터 전송 가능
* DMA의 우선순위는 메모리 참조의 경우 중앙처리장치보다 상대적으로 높음
* 인터럽트 신호를 발생시켜 CPU에게 입출력 종료를 알림
* **Cycle Steal** 방식을 이용하여 데이터 전송 
  * CPU와 DMA 방식의 입출력 장치가 공통된 버스를 통해 주기억장치에 연결된 경우, 우선순위가 높은 입출력 채널이 접근 사이클을 먼저 사용하여 주기억장치에 접근하는 것 >> 작업 효율성 UP, CPU의 양보

**Channel I/O**

* I/O를 위한 특별 명령어를 I/O 프로세스에게 수행토록 하여 CPU 관여없이 주기억장치와 입출력장치 사이에서 입출력을 제어하는 입출력 전용 프로세서(IOP)
* 채널 제어기는 채널 명령어로 작성된 채널 프로그램을 해독하고 실행하여 입출력 동작 처리
* CPU로부터 입출력 전송을 위한 명령어를 받으면 CPU와는 독립적으로 동작하여 입출력 완료
* 채널을 주기억장치에 기억되어 있는 채널 프로그램의 수행과 자료 전송을 위해 주기억장치 직접 접근
* 채널의 종류
  * Selector Channel : 고속 입출력장치(자기디스크, 자기테이프, 자기드럼) 1개와 입출력하기위해 사용
  * Multiplexer Channel : 저속 입출력장치(카드리더, 프린터) 여러개를 동시에 제어하는 채널
  * Block Multiplexer Channel : 동식에 여러 개의 고속 입출력 장치 제어

**Isolated I/O**

* 입출력 장치들이 입출력 버스를 통해 CPU와 연결되어 있는 경우
* 메모리는 따로 메모리 버스를 통해 연결
* 입출력은 입출력을 담당하는 명령어를 통해 실행/입출력버스를 통해 해당 장치의 지정, 데이터, 입출력 구분 제어값 전달
* 입출력 명령어가 명령어 집합에 추가되어 제어로직 복잡
* 입출력 버스를 장착하는데 추가비용

**Memory-mapped I/O**

* CPU가 입출력 장치를 엑세스할 때, 입출력과 메모리의 주소공간을 공동 데이터버스, 주소버스, 제어버스 등으로 구분하지 않고 하나의 메모리 공간에 취급하여 배치하는 방식
* 입출력을 위한 명령어를 따로 사용않고, 메모리에 대한 명령어를 활용하여 입출력 수행
* 입출력 장치들은 각각 메모리의 한 번지를 할당받아 입출력 수행하기에 메모리를 동적으로 사용 불가

---

### MBR

> Master Boot Record

* 부팅 시, OS가 메모리에 적재될 수 있도록 디스크의 시작 섹터에 위치하고 있다.
* BIOS는 ROM에 적재되어 있고 각 장치의 부트로드 이전에 데이터흐름을 세팅한다.

---

### MMU

> Memory Management Unit

* 가상 메모리의 주소를 물리 주소로 변환하는 기능

**Shadowing**

* 실행파일 전체를 DRAM에 올리고 사용하는 것
* RAM 용량이 제한적인데다가, SW크기는 점점 커지는 경우 Shadowing은 불가능

**Demand Paging**

* Shadowing의 한계를 극복하기 위해 사용
* 요구 페이징을 위해 MMU를 필요로 한다.

**TLB**

* 자주 참조되는 가상 메모리 주소를 실제 메모리 주소로 매핑 시 성능 개선 위해 MMU에서 사용하는 **고속 캐시**

---

### Critical Section

 **1. 상호 배제(mutual exclusive)** : 한 프로세스가 임계 구역에서 실행하고 있으면 어떤 프로세스도 임계 구역에 진입할 수 없어야 한다. SW로 가능하지만, 매우 복잡하여 HW로 대부분 보조한다.

 **2. 진행(progress)** : 임계 영역 안에서 실행하고 있는 프로세스가 없는 경우, 임계 영역을 실행하고자 하는 프로세스는 반드시 임계 영역을 실행할 수 있어야 한다. 이를 만족하면 진행 조건을 만족한다고 할 수 있다. 

 **3. 한계 대기(bounded waiting)** : 임계 영역을 요청한 프로세스는 무한히 대기하면 안된다. 즉, 제한된 대기 시간을 가져야 한다. 이를 만족하면 한정 대기 조건을 만족한다고 할 수 있다.

<br>

**프로세스 동기화 기법**

* SW 기반
  * Mutex
    * 한 개의 키
    * 데커 알고리즘
    * 피터슨 알고리즘
    * acquire하려는 프로세스는 무한 루프를 돌며 busy waiting을 해야한다.
      * mutex lock을 **spinlock**이라고 부르기도 하는 이유이다
  * 세마포어
    * 여러개의 키를 이용가능
    * 세마포어는 뮤텍스가 될 수 있지만 그 역은 성립하지 않는다.
    * acquire하려는 프로세스는 무한 루프를 돌며 busy waiting을 해야한다.
  * 모니터
    * 외부에서 모니터 내부 지역변수에 접근 할 수 없다.
    * 프로세스는 모니터의 프로시저를 호출함으로써 모니터 내부로 접근 한다.
    * 한 순간에 오직 하나의 프로세스만이 모니터 내에 존재할 수 있다. (상호배제 실현)
    * 초기화 코드 : 모니터 초기 생성에 사용된다. 프로시저를 통해 공유 데이터에 접근가능.

---

### 부동소수점(IEEE 754)

**특징**

* 32비트로 구성
* 0은 특별한 값으로 정의한다.

**구성**

* 부호부 (1비트) : 양수일 때는 0, 음수일 때는 1
* 지수부 (부호가 있는 정수, 8비트) : 제일 앞의 1비트는 부호를 정하고, 나머지 7비트로 표시
* 정규화된 가수부 (부호가 없는 정수, 23비트) : 제일 앞의 비트는 정규화되었으므로 1이다.

**Why?**

* 고정 소수점과는 다르게, 표현할 수 있는 수의 범위가 굉장히 넓어진다. (현재 모든 프로그래밍 언어, 그래픽, 공학 프로그램등이 준수하는 국제 표준 IEEE-754로 지정되어 있음)
* 가수부가 지수부보다 길어서 **정밀도가 비교적 충분**
* 즉, 보다 효율적으로 **긴 소수점(유효숫자)**을 표현하기 위해서 사용한다.

---

### DeadLock

**해결방법**

* 예방(Prevention)
  * 네 가지 필수 조건 중 하나 이상을 부정하여 방지
  * 가장 자원낭비가 많음
* 회피(Avoidance)
  * 교착 상태가 발생하기 전에 교착 상태를 예상하여 안전한 상태(safe state)에서만 자원 요청을 허용
  * 은행원 알고리즘, 자원할당 그래프
* 탐지(Detection)
  * 교착 상태 탐지는 탐지 알고리즘을 사용하여 교착상태가 발생했는지 탐지
  * 지속적으로 확인하는 작업이 필요하기 때문에 성능 저하가 발생
  * 대기 그래프
* 복구(Recovery)
  * 교착 상태를 일으킨 프로세스를 종료하거나, 할당된 자원을 해제함으로써 복구

---

### Thrashing

* 메모리 영역에 접근하게 될 때, 메모리에 페이지 부재율이 높은 것

**해결방법**

* **PFF(Page Fault Frequency)**
  * pagefault가 **자주**일어나면 메모리를 더 주고, **자주** 일어나지 않으면 메모리를 뺏는다
  * Working Set Model에 비해 Overhead가 작고 직접 페이지 부재율을 조절할 수 있다.
* **Working Set**
  * 프로세스가 많이 참조하는 페이지 집합을 메모리 공간에 계속 상주시켜 빈번한 페이지 교체현상을 줄이는 방법

---

### Memory

**Linker**

* 링커는 컴파일러가 생성한 목적 프로그램들과 라이브러리, 또 다른 실행 프로그램(로드 모듈) 등을 연결하여 실행 가능한 로드 모듈(.EXE)을 만드는 시스템 소프트웨어


**Loader**

1. **할당(allocation)** : 목적 프로그램이 적재될 주기억 장소 내의 공간을 확보
2. **연결(linking)** : 필요할 경우 여러 목적 프로그램들 또는 라이브러리 루틴과의 링크 작업. 외부기호를 참조할 때, 이 주소 값들을 연결
3. **재배치(relocation)** : 목적 프로그램을 실제 주기억 장소에 맞추어 재배치. 상대주소들을 수정하여 절대주소로 변경
4. **적재(loading)** : 실제 프로그램과 데이터를 주기억 장소에 적재. 적재할 모듈을 주기억장치로 읽어 들임

**Loader의 종류**

* Compile and Go : **컴파일러가 로더의 역할**까지 담당하는 것으로 프로그램의 크기가 크고 한 가지 언어로만 프로그램을 작성할 수 있다. 실행을 원할 때마다 번역을 해야 한다. 이러한 특성 때문에 로더라고 하기에는 부적합
* 절대로더(absolute loader) : 단순히 번역된 목적프로그램을 입력으로 받아들여 주기억장치의 **프로그래머가 지정한 주소**에 적재하는 기능을 가지는 간단한 로더
  * 작업분담
    * 링크 - 프로그래머
    * 기억장소 할당 - 프로그래머
    * 재배치 - 어셈블러
    * 적재 - 로더
* 재배치 로더 (relocating loader) : 주기억 장치의 상태에 따라 목적 프로그램을 주기억 장치의 임의의 공간에 적재할 수 있도록 하는 로더
  * 작업분담
    - 링크-링커
    - 기억장소 할당-운영체제
    - 재배치-로더
    - 적재-로더
* 링킹로더 (linking loader) : 하나의 부프로그램이 변경되어도 다른 모듈 프로그램을 다시 번역할 필요가 없도록 프로그램에 대한 기억장소할당과 부 프로그램의 연결이 로더에 의해 자동으로 수행되는 프로그램으로 직접연결로더(Direct Linking Loader)가 대표적임
  * 작업분담
    - 링크-링킹로더
    - 기억장소 할당-운영체제
    - 재배치-링킹로더
    - 적재-링킹로더
* 동적 적재(Dynamic Loading = Load on call) : 모든 세그먼트를 주기억장치에 적재하지 않고 항상 필요한 부분만 주기억장치에 적재하고 나머지는 보조기억 장치에 저장해두는 기법

---

### 인터럽트

**동기 인터럽트**

* 명령어 실행 중 CPU에 의해 처리되는 인터럽트로 하나의 명령어가 종료 후 인터럽트가 발생한다. 
* EX
  * 0으로 나누기
  * 프로세스 내 명령어 실행에 의한 발생하는 인터럽트
  * 프로세스 내 명령어가 보호 메모리영역을 참조할 때 발생하는 인터럽트

**비동기 인터럽트**

* 다른 하드웨어 장치가 CPU 클럭시 시그널과 상관없이 생성하는 인터럽트이다. 키보드 혹은 마우스를 사용할 때 발생하는 것과 같은 인터럽트를 말한다.

---





